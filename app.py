import pydantic.v1
import streamlit as st
from langchain_groq import ChatGroq
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate
import os
import pickle
import re;
from dotenv import load_dotenv
import fitz
from HTMLTEMPLATE import css
from langchain.schema import Document
import pytesseract
from PIL import Image




pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # ุบููุฑ ุงููุณุงุฑ ุญุณุจ ููุงู ุงูุชุซุจูุช ุนูุฏู


def prepare_ocr_for_lm(text):
    """
    ุชูุธูู ุงููุต ุงููุงุชุฌ ูู OCR ูุจู ุฅุฑุณุงูู ูููููุฐุฌ
    """
    text = re.sub(r"\s{2,}", " ", text)
    text = re.sub(r"[^\u0600-\u06FF0-9A-Za-z\s.,()\-โโ/]", "", text)
    return text.strip()




def GET_TEXT_FROM_PDF(PDFS):
    """
    ๐ ุงุณุชุฎุฑุงุฌ ุงููุต ูู ูููุงุช PDF
    """
    full_text = ""

    for pdf in PDFS:
        pdf.seek(0)
        pdf_hash = hash(pdf.name)
        cache_file = f"cache_{pdf_hash}_smartocr.pkl"

        if os.path.exists(cache_file):
            with open(cache_file, "rb") as f:
                cached_text = pickle.load(f)
            st.info(f"๐ฆ ุชู ุชุญููู ุงููุต ูู ุงูุฐุงูุฑุฉ ุงููุคูุชุฉ (Smart OCR Cache): {pdf.name}")
            full_text += cached_text
            continue

        pdf_text = ""

        doc = fitz.open(stream=pdf.read(), filetype="pdf")
        for i, page in enumerate(doc, start=1):
            text = page.get_text("text")
            if len(text.strip()) > 0:
                st.info(f"๐ ุงูุตูุญุฉ {i}: ุชุญุชูู ุนูู ูุต ูุงุจู ูููุณุฎ โ")
                pdf_text += text + "\n"
                continue

            st.info(f"โ ุงูุตูุญุฉ {i}: ูุง ุชุญุชูู ุนูู ูุตุ ุณูุชู ุงุณุชุฎุฏุงู Tesseract OCR...")

            pix = page.get_pixmap(dpi=200)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

            try:
                extracted = pytesseract.image_to_string(img, lang="ara+eng")
            except Exception as e:
                st.error(f"โ ูุดู Tesseract OCR: {e}")
                extracted = ""

            if extracted.strip():
                pdf_text += extracted + "\n"
                st.success(f"โ ุชู ุชุญููู ุงูุตูุญุฉ {i} ูุงุณุชุฎุฑุงุฌ ุงููุต ({len(extracted)} ุญุฑู).")
            else:
                st.warning(f"โ ุงูุตูุญุฉ {i}: ูู ูุชููู OCR ูู ุงุณุชุฎุฑุงุฌ ุฃู ูุต.")

        pdf_text = re.sub(r"\s{2,}", " ", pdf_text).strip()

        with open(cache_file, "wb") as f:
            pickle.dump(pdf_text, f)

        full_text += pdf_text + "\n"

    st.success(f"๐ ุชู ุงุณุชุฎุฑุงุฌ ุงููุต ุจุงููุงูู ({len(full_text)} ุญุฑู).")

    cleaned_text = prepare_ocr_for_lm(full_text)
    return cleaned_text




def SPLITTEXTTOCHUNK(TEXT):
  SPLITTER = RecursiveCharacterTextSplitter(
    chunk_size=3500,
    chunk_overlap=500,
    separators=["\n", "ุงููุงุฏุฉ", ".", "ุ", " "]
  )
  CHUNK = SPLITTER.split_text(TEXT)
  return CHUNK


def CREATESTORE(TEXT, filename):
    """
    ๐ง ุฅูุดุงุก ุฃู ุชุญููู ูุงุนุฏุฉ ุจูุงูุงุช FAISS ุฎุงุตุฉ ุจูู ููู PDF.
    - ูุชู ุญูุธ ูู ููู ุฏุงุฎู ูุฌูุฏ faiss_index ุจุงุณู ุงูููู.
    """
    # ูุณุงุฑ ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจุงูููู
    os.makedirs("faiss_index", exist_ok=True)
    PATH = os.path.join("faiss_index", f"{filename}")

    # ุงุฎุชูุงุฑ ูููุฐุฌ Embedding
    EMBEDDING = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    # ุงูุชุฃูุฏ ูู ูุฌูุฏ ููู ุงูููุฑุณ ูุจู ุงูุชุญููู
    if os.path.exists(f"{PATH}.index.faiss") and os.path.exists(f"{PATH}.index.faiss"):
        STORE = FAISS.load_local(PATH, EMBEDDING, index_name=filename ,allow_dangerous_deserialization=True)
        st.info(f"๐ฆ ุชู ุชุญููู ูุงุนุฏุฉ ุจูุงูุงุช {filename}")
    else:
        st.info(f"โ ุฌุงุฑู ุฅูุดุงุก ูุงุนุฏุฉ ุจูุงูุงุช ุฌุฏูุฏุฉ ููููู: {filename} ...")
        STORE = FAISS.from_texts(TEXT, embedding=EMBEDDING)
        STORE.save_local("faiss_index", index_name=filename)
        st.success(f"๐พ ุชู ุญูุธ ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจุงูููู {filename} ุจูุฌุงุญ.")

    return STORE




def ASK_PDF_QUESTION(STORE, user_question):
    """
    ๐น ุงูุฏุงูุฉ ุฏู ุจุชุณุชูุจู ุณุคุงู ุงููุณุชุฎุฏูุ ูุชุณุชุฎุฏู ูุงุนุฏุฉ ุงูุจูุงูุงุช (FAISS)
    ุนูุดุงู ุชุฏูุฑ ุนูู ุฃูุณุจ ุฌุฒุก ูู ุงููุต ูุชุฌูุจ ุฅุฌุงุจุฉ ุฐููุฉ ูู ููุฏูู Groq.
    """

    # ูุจุญุซ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุนู ุงููุตูุต ุงูุฃูุฑุจ ููุณุคุงู
    docs = STORE.similarity_search(user_question, k=2)

    recent_context_text = ""
    if "chat_history" in st.session_state and len(st.session_state.chat_history) > 0:
        # ุฎุฐ ุขุฎุฑ 2 ูุญุงุฏุซุงุช (user+assistant)
        for chat in st.session_state.chat_history[-2:]:
            q = chat.get("question", "")
            a = chat.get("answer", "")
            recent_context_text += f"ูุญุงุฏุซุฉ ุณุงุจูุฉ โ ุณุคุงู ุงููุณุชุฎุฏู: {q}\nุฑุฏ ุงููุณุงุนุฏ: {a}\n\n"

    if recent_context_text:
        docs.append(Document(page_content=recent_context_text, metadata={"source": "recent_conversation"}))


    # ูุญุฏุฏ ุดูู ุงูุจุฑููุจุช (ุทุฑููุฉ ููู ุงูุณุคุงู)


    PROMPT = """
ุฃูุช ูุณุงุนุฏ ุฐูู ูุชุฎุตุต ูู ุชุญููู ุงููุตูุต ุงููุงููููุฉุ ุงููุงููุฉุ ูุงูุฅุฏุงุฑูุฉ.
ูููุชู ููู ุงููุตูุต ูุชุญููููุง ุจุฏูุฉ ูุงุณุชุฎูุงุต ุงูุฅุฌุงุจุงุช ุงููุทููุจุฉ ุจูุถูุญ ูุชูุธูู.

๐ฏ ุงูุฃุณููุจ:
- ุชูุงุนู ุจููุทู ูุงุญุชุฑุงููุฉุ ูุชูููู ูุน ุฃุณููุจ ุงููุณุชุฎุฏู (ุนุงููุฉ ุฃู ูุตุญู).
- ุงุณุชุฎุฏู ููุฌุฉ ูุฏููุฉ ุนูุฏ ุงูุฃุณุฆูุฉ ุงูุนุงูุฉุ ููุตุญู ุฏูููุฉ ุนูุฏ ุงูุชุญููู.
- ูู ุฅูุฌุงุจููุง ููุญูุฒูุง ("ุชูุงู ูุง ุจุทู ๐"ุ "ูููู ููุชุงุฒ ๐ช").
- ุงุณุชุฎุฏู ุงูุฅูููุฌู ููุชุฑููู ูุงูุชูุธูู (1๏ธโฃุ 2๏ธโฃุ ๐กุ โ๏ธ...).
- ุงุฌุนู ุงูุฅุฌุงุจุงุช ูุฑุชุจุฉ ุจุนูุงููู ูุงุถุญุฉ: โ๏ธ ุงูุชุญููู ุงููุงูููู / ๐ฐ ุงูุชุญููู ุงููุงูู / ๐ ุงูููุฎุต ุงูุชูููุฐู.

๐ ุงููุจุงุฏุฆ:
- ุงุนุชูุฏ ููุท ุนูู ุงููุต ุงูููุฏู ุฏูู ูุนูููุงุช ุฎุงุฑุฌูุฉ.
- ูุถูุญ ุฅู ูุงูุช ุงูุฅุฌุงุจุฉ ูู ูุต ุตุฑูุญ ุฃู ูู ุงุณุชูุชุงุฌ ("ููููู ูู ุงูุณูุงู ุฃู...").
- ูุณูุฑ ุงูุชุนุฏููุงุช ุงููุงููููุฉ ุจุฐูุฑ ุงููุงุฏุฉ ุงูุฃุตููุฉ ูุงูุชุนุฏูู ุงูุฌุฏูุฏ.
- ุญููู ุงูุนูุงูุฉ ุจูู ุงูููุงุฏ (ุชุนุฏููุ ุฅูุบุงุกุ ุฅุญุงูุฉ...).
- ุงุณุชูุชุฌ ุงูุฃุณููุจ ุงูุนุงู ูููุต (ุฑุณููุ ุฃูุงุฏูููุ ุฅุฏุงุฑู...).
- ูู ุฏููููุง ูู ุงูุญุณุงุจุงุช ุงููุงููุฉ ูุงูุถุฑูุจูุฉุ ููุถูุญ ุงูุฎุทูุงุช ุงูุญุณุงุจูุฉ ุจุชุฑุชูุจ ููุทูู.
- ุนูุฏ ูุฌูุฏ ูุต ุบูุฑ ูุงุถุญ ุฃู ูุงุชุฌ ุนู OCRุ ุงุณุชูุชุฌ ุงููููุฉ ุงูููููุฏุฉ ุจูู ููุณูู ุฏูู ุงุฎุชูุงู ูุนูููุฉ.

๐ ุทุฑููุฉ ุงูุนุฑุถ:
1๏ธโฃ ุชุญููู ููุธู ุจุฎุทูุงุช ูุฎุชุตุฑุฉ.
2๏ธโฃ ุงูุฌุฏุงูู ุชูุณุชุฎุฏู ููุฃุฑูุงู ุฃู ุงูููุงุฏ ุงููุงููููุฉ.
3๏ธโฃ ุงูุญุณุงุจุงุช ุงููุงููุฉ ุชูุถูุญ ูุงูุชุงูู:
   - ุงููููุฉ ุงูุฃุตููุฉ  
   - ุงููุณุจุฉ ุงููุทุจูุฉ  
   - ุงููุงุชุฌ ุงูููุงุฆู
4๏ธโฃ ุฃุถู ููุฑุฉ ูู ุงูููุงูุฉ ุจุนููุงู:  
   **๐ ุงูุฎูุงุตุฉ:** (ุณุทุฑูู ูุฃูู ุงูููุงุท).

๐ง ุฃุณููุจ ุงูุชูููุฑ:
- ุญููู ุฃูููุง ุงููุนููุ ุซู ุงูุชุทุจูู ุงูุนููู.
- ูุถูุญ ุงููุฑูู ุฃู ุงูุนูุงูุงุช ุจูู ุงูููุงุฏ ุนูุฏ ุงูุญุงุฌุฉ.
- ุนูุฏ ุงูุบููุถุ ุจููู ุญุฏูุฏ ุงููููู ุจูุฏูุก.

ุงููุนุทูุงุช:
{context}

ุณุคุงู ุงููุณุชุฎุฏู:
{question}

ุงูุฅุฌุงุจุฉ:
"""





    # ูุนูู ูุงูุจ (Template) ููุฏุฑ ููุฑุฑ ูู ุงููุต ูุงูุณุคุงู
    prompt = PromptTemplate(template=PROMPT, input_variables=["context", "question"])

    # ูุฎุชุงุฑ ููุฏูู Groq (ุชูุฏุฑ ุชุบููุฑ ููุนู ุญุณุจ ุงุญุชูุงุฌู)
    model = ChatGroq(
        model="openai/gpt-oss-120b",  # ููุฏูู ุฐูู ูููุงุณุจ ููุฃุณุฆูุฉ ุงูุชุญููููุฉ
        # model="openai/gpt-oss-20b",  # ููุฏูู ุฐูู ูููุงุณุจ ููุฃุณุฆูุฉ ุงูุชุญููููุฉ
        # model="meta-llama/llama-4-maverick-17b-128e-instruct",  # ููุฏูู ุฐูู ูููุงุณุจ ููุฃุณุฆูุฉ ุงูุชุญููููุฉ
        # model="moonshotai/kimi-k2-instruct",  # ููุฏูู ุฐูู ูููุงุณุจ ููุฃุณุฆูุฉ ุงูุชุญููููุฉ
        temperature=0.2,       # ุฑูู ููุฎูุถ ูุนูู ุฅุฌุงุจุงุช ุฏูููุฉ ูุซุงุจุชุฉ
        groq_api_key=os.getenv("GROQ_API_KEY")  # ููุชุงุญ ุงูู API ูู ูุชุบูุฑ ุงูุจูุฆุฉ
    )

    # ูุญูู ุณูุณูุฉ ุณุคุงู ูุฌูุงุจ ุชุฑุจุท ุงูููุฏูู ุจุงูุจุฑููุจุช
    chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)

    # ูุฑุณู ุงูุณุคุงู ููููุฏูู ูุน ุงููุตูุต ุงููุฑุชุจุทุฉ ุจู
    response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)

    # ูุฑุฌุน ุงููุต ุงูููุงุฆู ุงููุงุชุฌ ูู ุงูููุฏูู
    return response["output_text"]



def main():
  load_dotenv()
  st.set_page_config("ุงูุฑูุจูุช ุงูุฐูู", page_icon="๐ค")
  if "chat_history" not in st.session_state:
      st.session_state.chat_history = []
  st.title("๐ค ุงููุณุชุดุงุฑ ุงููุงูููู ุงูุฐูู")
  st.markdown("""
          <p style='text-align: center; color: #FFF7; font-family: Tajawal'>
            ุงุฑูุน ูููุงุชู ูุงุณุฃู ุฃู ุณุคุงู ุนููุง โ ุณูููู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุจุงูุฅุฌุงุจุฉ ุงุณุชูุงุฏูุง ุฅูู ูุญุชูู ุงูููู.
        </p>
""", True)
  st.write(css, unsafe_allow_html=True)
  st.markdown("""<div class='overlay'></div>""", True)
  PDFS = st.file_uploader("ุงุฑูุน ูููุงุชู ูู ููุง", type="pdf", accept_multiple_files=True)
  if PDFS:
    with st.spinner("โณ ุฌุงุฑู ุงููุนุงูุฌุฉ... "):
      #ุงุณุชุฎุฑุงุฌ ุงูููุงู ูู ุงููููุงุช ุงู PDF
      GET_TEXT = GET_TEXT_FROM_PDF(PDFS)

      # ุชูุณูู ุงููููุงุช ุนูู ุดูู ููุงุทุน
      SPLIT_TEXT_TO_CHUNK = SPLITTEXTTOCHUNK(GET_TEXT)
      for PDF in PDFS:
        filename = os.path.splitext(PDF.name)[0]
        STORE = CREATESTORE(SPLIT_TEXT_TO_CHUNK, filename)
      # ุงูุดุงุก ูุงุนุฏุฉ ุจูุงูุงุช

    user_question = st.chat_input("ุฃุณุงู ุณุคุงูู ููุง")
    if (user_question):

        answer = ASK_PDF_QUESTION(STORE, user_question)
        st.session_state.chat_history.append({
            "question": user_question ,
            "answer": answer
        })
        if st.session_state.chat_history:
            for chat in st.session_state.chat_history:
              # ๐น ูุญูู ุฃู ูููู ูุตู ุฅูู ุฑุงุจุท HTML ูุงุจู ููุถุบุท
              def make_links_clickable(text):
                # ูุญููู ุฃู ูููู (ุญุชู ุงููู ูู ุบูุฑ http) ุฅูู ุฑุงุจุท ูุงุจู ููุถุบุท
                url_pattern = r'((?:https?://)?(?:www\.)?[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}(?:/[^\s<>"]*)?)'
                def repl(match):
                  url = match.group(0)
                  if not url.startswith("http"):
                    url = "https://" + url
                  return f'<a href="{url}" target="_blank" style="color:#4fc3f7; text-decoration:underline;">{match.group(0)}</a> ๐'
                return re.sub(url_pattern, repl, text)


              st.markdown(f"""
        <div style='background-color:rgb(255 255 255 / 4%); backdrop-filter: blur(10px); font-size:18px ;  color:#FFF; direction: rtl ; font-family:tajawal ;padding:10px; border-radius:10px; margin-top:10px;'>
            <span style="color: rgb(197 197 197); margin-bottom: 6px; display:inline-block; font-weight:bold"> ๐โโ๏ธ ุณุคุงูู</span><br>{chat["question"]}
                    </div>
  """, unsafe_allow_html=True)
              st.markdown(f"""
            <div style='background-color:#FFF1; font-size:18px ;color:#FFF; direction: rtl ;  font-family:tajawal ;padding:10px; border-radius:10px; margin-top:10px;'>
                        <span style='color:#009688; margin-bottom: 6px; display:inline-block; font-weight:bold'>๐ค ุฑุฏ ุงููุณุชุดุงุฑ ุงููุงูููู</span><br>{make_links_clickable(chat["answer"])}
                        </div>
  """, unsafe_allow_html=True)



if __name__ == "__main__":
  main()