import pydantic.v1
import streamlit as st
from langchain_groq import ChatGroq
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate
import os
import pickle
import re;
from dotenv import load_dotenv
import fitz
from HTMLTEMPLATE import css
from langchain.schema import Document
# import pytesseract
# from PIL import Image




# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # ØºÙŠÙ‘Ø± Ø§Ù„Ù…Ø³Ø§Ø± Ø­Ø³Ø¨ Ù…ÙƒØ§Ù† Ø§Ù„ØªØ«Ø¨ÙŠØª Ø¹Ù†Ø¯Ùƒ


def prepare_ocr_for_lm(text):
    """
    ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ø§ØªØ¬ Ù…Ù† OCR Ù‚Ø¨Ù„ Ø¥Ø±Ø³Ø§Ù„Ù‡ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
    """
    text = re.sub(r"\s{2,}", " ", text)
    text = re.sub(r"[^\u0600-\u06FF0-9A-Za-z\s.,()\-â€“â€”/]", "", text)
    return text.strip()




def GET_TEXT_FROM_PDF(PDFS):
    """
    ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„ÙØ§Øª PDF
    """
    full_text = ""

    for pdf in PDFS:
        pdf.seek(0)
        pdf_hash = hash(pdf.name)
        cache_file = f"cache_{pdf_hash}_smartocr.pkl"

        if os.path.exists(cache_file):
            with open(cache_file, "rb") as f:
                cached_text = pickle.load(f)
            st.info(f"ğŸ“¦ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© (Smart OCR Cache): {pdf.name}")
            full_text += cached_text
            continue

        pdf_text = ""

        doc = fitz.open(stream=pdf.read(), filetype="pdf")
        for i, page in enumerate(doc, start=1):
            text = page.get_text("text")
            if len(text.strip()) > 0:
                st.info(f"ğŸ“„ Ø§Ù„ØµÙØ­Ø© {i}: ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Øµ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù†Ø³Ø® âœ…")
                pdf_text += text + "\n"
                continue

            st.info(f"âš™ Ø§Ù„ØµÙØ­Ø© {i}: Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract OCR...")

            # pix = page.get_pixmap(dpi=200)
            # img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

            # try:
            #     extracted = pytesseract.image_to_string(img, lang="ara+eng")
            # except Exception as e:
            #     st.error(f"âŒ ÙØ´Ù„ Tesseract OCR: {e}")
            #     extracted = ""

            # if extracted.strip():
            #     pdf_text += extracted + "\n"
            #     st.success(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© {i} ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ ({len(extracted)} Ø­Ø±Ù).")
            # else:
            #     st.warning(f"âš  Ø§Ù„ØµÙØ­Ø© {i}: Ù„Ù… ÙŠØªÙ…ÙƒÙ† OCR Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù†Øµ.")

        pdf_text = re.sub(r"\s{2,}", " ", pdf_text).strip()

        with open(cache_file, "wb") as f:
            pickle.dump(pdf_text, f)

        full_text += pdf_text + "\n"

    st.success(f"ğŸ“˜ ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ ({len(full_text)} Ø­Ø±Ù).")

    cleaned_text = prepare_ocr_for_lm(full_text)
    return cleaned_text




def SPLITTEXTTOCHUNK(TEXT):
  SPLITTER = RecursiveCharacterTextSplitter(
    chunk_size=3500,
    chunk_overlap=500,
    separators=["\n", "Ø§Ù„Ù…Ø§Ø¯Ø©", ".", "ØŒ", " "]
  )
  CHUNK = SPLITTER.split_text(TEXT)
  return CHUNK


def CREATESTORE(TEXT, filename):
    """
    ğŸ§  Ø¥Ù†Ø´Ø§Ø¡ Ø£Ùˆ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª FAISS Ø®Ø§ØµØ© Ø¨ÙƒÙ„ Ù…Ù„Ù PDF.
    - ÙŠØªÙ… Ø­ÙØ¸ ÙƒÙ„ Ù…Ù„Ù Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ faiss_index Ø¨Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù.
    """
    # Ù…Ø³Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ù„Ù
    os.makedirs("faiss_index", exist_ok=True)
    PATH = os.path.join("faiss_index", f"{filename}")

    # Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Embedding
    EMBEDDING = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„ÙÙ‡Ø±Ø³ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„
    if os.path.exists(f"{PATH}.index.faiss") and os.path.exists(f"{PATH}.index.faiss"):
        STORE = FAISS.load_local(PATH, EMBEDDING, index_name=filename ,allow_dangerous_deserialization=True)
        st.info(f"ğŸ“¦ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª {filename}")
    else:
        st.info(f"âš™ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù…Ù„Ù: {filename} ...")
        STORE = FAISS.from_texts(TEXT, embedding=EMBEDDING)
        STORE.save_local("faiss_index", index_name=filename)
        st.success(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ù„Ù {filename} Ø¨Ù†Ø¬Ø§Ø­.")

    return STORE




def ASK_PDF_QUESTION(STORE, user_question):
    """
    ğŸ”¹ Ø§Ù„Ø¯Ø§Ù„Ø© Ø¯ÙŠ Ø¨ØªØ³ØªÙ‚Ø¨Ù„ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ ÙˆØªØ³ØªØ®Ø¯Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (FAISS)
    Ø¹Ù„Ø´Ø§Ù† ØªØ¯ÙˆØ± Ø¹Ù„Ù‰ Ø£Ù†Ø³Ø¨ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ ÙˆØªØ¬ÙŠØ¨ Ø¥Ø¬Ø§Ø¨Ø© Ø°ÙƒÙŠØ© Ù…Ù† Ù…ÙˆØ¯ÙŠÙ„ Groq.
    """

    # Ù†Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø£Ù‚Ø±Ø¨ Ù„Ù„Ø³Ø¤Ø§Ù„
    docs = STORE.similarity_search(user_question, k=2)

    recent_context_text = ""
    if "chat_history" in st.session_state and len(st.session_state.chat_history) > 0:
        # Ø®Ø° Ø¢Ø®Ø± 2 Ù…Ø­Ø§Ø¯Ø«Ø§Øª (user+assistant)
        for chat in st.session_state.chat_history[-2:]:
            q = chat.get("question", "")
            a = chat.get("answer", "")
            recent_context_text += f"Ù…Ø­Ø§Ø¯Ø«Ø© Ø³Ø§Ø¨Ù‚Ø© â€” Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {q}\nØ±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯: {a}\n\n"

    if recent_context_text:
        docs.append(Document(page_content=recent_context_text, metadata={"source": "recent_conversation"}))


    # Ù†Ø­Ø¯Ø¯ Ø´ÙƒÙ„ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª (Ø·Ø±ÙŠÙ‚Ø© ÙÙ‡Ù… Ø§Ù„Ø³Ø¤Ø§Ù„)

    PROMPT = """
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…ØªØ®ØµØµ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ù…Ø®ØªÙ„Ù Ø£Ù†ÙˆØ§Ø¹Ù‡Ø§ (Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©ØŒ Ù…Ø§Ù„ÙŠØ©ØŒ Ø¥Ø¯Ø§Ø±ÙŠØ©ØŒ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©ØŒ Ø£Ùˆ Ø´Ø®ØµÙŠØ©). 
Ù…Ù‡Ù…ØªÙƒ ÙÙ‡Ù… Ø§Ù„Ù†Øµ ÙˆØªØ­Ù„ÙŠÙ„Ù‡ Ø¨Ø¹Ù…Ù‚ Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø¯Ù‚Ø© ÙˆØªÙ†Ø¸ÙŠÙ….

âš™ï¸ Ù‚ÙˆØ§Ø¹Ø¯ Ø£Ø³Ø§Ø³ÙŠØ©:
- Ø§Ù„Ù…ØªØºÙŠØ± {context} ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ù…Ù„Ù Ø£Ùˆ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ø°ÙŠ Ø±ÙØ¹Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù….
- Ø¥Ø°Ø§ ÙƒØ§Ù† {context} ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙŠ Ù†Øµ (Ø­ØªÙ‰ Ù„Ùˆ Ù‚ØµÙŠØ± Ø£Ùˆ Ø¨Ø³ÙŠØ·) â†’ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙˆØ±Ù‹Ø§.
- Ù„Ø§ ØªØ¹ØªØ¨Ø± Ø§Ù„Ù†Øµ ÙØ§Ø±ØºÙ‹Ø§ Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø­Ø±ÙÙŠÙ‹Ø§ ÙØ§Ø±ØºÙ‹Ø§ ØªÙ…Ø§Ù…Ù‹Ø§ ("").
- Ù„Ø§ ØªÙƒØ±Ø± Ø¹Ø¨Ø§Ø±Ø© "Ù„Ù… Ø£Ø³ØªÙ„Ù… Ù†Øµ Ø§Ù„Ù…Ù„Ù" Ø¥Ù„Ø§ ÙÙŠ Ø­Ø§Ù„Ø© Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø£ÙŠ Ù…Ø­ØªÙˆÙ‰ Ø¥Ø·Ù„Ø§Ù‚Ù‹Ø§.
- Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ {context}.

ğŸ¯ Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªÙØ§Ø¹Ù„:
- Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù„ÙˆØ¨ ÙˆØ¯Ù‘ÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¹Ù†Ø¯ Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø¹Ø§Ù…ÙŠØ© Ø£Ùˆ ÙØµØ­Ù‰ Ø­Ø³Ø¨ Ø³ÙŠØ§Ù‚Ù‡).
- Ø¹Ù†Ø¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© ÙØµØ­Ù‰ Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙˆØ§Ø¶Ø­Ø©.
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ù„Ù„ØªÙ†Ø¸ÙŠÙ… Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ© (âš–ï¸ØŒ ğŸ’°ØŒ ğŸ“ŠØŒ ğŸ§ ØŒ ğŸ’¡...).
- Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ù†Ø¸Ù…Ø© Ø¨Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ø¶Ø­Ø© Ù„Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…Ø®ØªÙ„ÙØ©.

ğŸ“˜ Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ø¹Ø§Ù…Ø©:
1ï¸âƒ£ Ø§Ø³ØªÙ†ØªØ¬ Ø£ÙˆÙ„Ù‹Ø§ Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ù…Ù† Ø§Ù„Ù†Øµ (Ù…Ø«Ù„Ø§Ù‹: Ù‚Ø§Ù†ÙˆÙ†ÙŠØŒ Ù…Ø§Ù„ÙŠØŒ Ø¥Ø¯Ø§Ø±ÙŠØŒ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØŒ Ø´Ø®ØµÙŠ...).
   - Ø£Ù…Ø«Ù„Ø©:
     - Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„ "Ù‚Ø§Ù†ÙˆÙ†ØŒ Ù…Ø§Ø¯Ø©ØŒ Ù‚Ø±Ø§Ø±" â†’ Ù‚Ø§Ù†ÙˆÙ†ÙŠ.
     - Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª Ø£Ø±Ù‚Ø§Ù… Ù…Ø§Ù„ÙŠØ© Ø£Ùˆ Ù†Ø³Ø¨ Ø£Ùˆ Ø¶Ø±Ø§Ø¦Ø¨ â†’ Ù…Ø§Ù„ÙŠ.
     - Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ø«Ù„ "Ø¥Ø¯Ø§Ø±Ø©ØŒ Ù…ÙˆØ¸ÙØŒ Ù‚Ø±Ø§Ø± Ø¥Ø¯Ø§Ø±ÙŠ" â†’ Ø¥Ø¯Ø§Ø±ÙŠ.
     - Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ø«Ù„ "Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ø§Ù„Ø¨ØŒ Ù…Ø´Ø±ÙˆØ¹ ØªØ®Ø±Ø¬" â†’ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ.
     - Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø®ØµÙŠØ© Ø£Ùˆ Ø³ÙŠØ±Ø© Ø°Ø§ØªÙŠØ© â†’ Ø´Ø®ØµÙŠ.
2ï¸âƒ£ Ù‚Ø¯Ù‘Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ù…ÙƒØªØ´Ù.
3ï¸âƒ£ ÙˆØ¶Ù‘Ø­ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¥Ù† ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…Ù† Ù†Øµ ØµØ±ÙŠØ­ Ø£Ùˆ Ù…Ù† Ø§Ø³ØªÙ†ØªØ§Ø¬ (Ù‚Ù„: "ÙŠÙÙÙ‡Ù… Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ Ø£Ù†...").
4ï¸âƒ£ Ù„Ø§ ØªØ®ØªÙ„Ù‚ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©.

ğŸ–‹ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¤Ù„Ù Ø£Ùˆ Ø§Ù„Ø¬Ù‡Ø©:
- Ø§Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ø«Ù„:
  "ØªØ£Ù„ÙŠÙ"ØŒ "Ø¥Ø¹Ø¯Ø§Ø¯"ØŒ "Ø¨Ù‚Ù„Ù…"ØŒ "ØªØ­Øª Ø¥Ø´Ø±Ø§Ù"ØŒ "Ø¥Ø´Ø±Ø§Ù"ØŒ "Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯"ØŒ "Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØªØ­Ø±ÙŠØ±"ØŒ "Ø¥Ø´Ø±Ø§Ù Ø§Ù„Ø£Ø³ØªØ§Ø°"ØŒ "Ø¥Ø´Ø±Ø§Ù Ø¯.".
- Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ø³Ù…ØŒ ÙØ±Ù‘Ù‚ Ø¨ÙŠÙ†Ù‡Ù… (Ù…Ø¤Ù„Ù / Ù…Ø´Ø±Ù / Ù…Ø¹Ø¯Ù‘).
- Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØ°ÙƒØ± Ø§Ø³Ù… ØµØ±ÙŠØ­ØŒ Ø§Ø³ØªÙ†ØªØ¬ Ø§Ù„Ø¬Ù‡Ø© Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ (Ù…Ø«Ù„ Ø§Ø³Ù… Ø¬Ø§Ù…Ø¹Ø© Ø£Ùˆ ÙˆØ²Ø§Ø±Ø© Ø£Ùˆ Ù…Ø¤Ø³Ø³Ø©).
- Ù„Ø§ ØªØ¶Ø¹ Ø£Ø³Ù…Ø§Ø¡ ØºÙŠØ± Ù…Ø°ÙƒÙˆØ±Ø© Ø£Ùˆ Ø¨Ù„Ø§ Ø¯Ù„ÙŠÙ„.

ğŸ“Š Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø±Ø¶:
Ø§Ø¨Ø¯Ø£ Ø¯Ø§Ø¦Ù…Ù‹Ø§ Ø¨Ù€:
ğŸ“„ **Ù†ÙˆØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯:** (Ø§Ø³ØªÙ†ØªØ§Ø¬Ùƒ Ù…Ù† Ø§Ù„Ù†Øµ)

Ø«Ù… Ø§Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø§Ù„ØªØ§Ù„ÙŠ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©:
- âš–ï¸ **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ**
- ğŸ’° **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ**
- ğŸ—‚ **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¯Ø§Ø±ÙŠ**
- ğŸ“š **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ**
- ğŸ‘¤ **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø®ØµÙŠ**
- ğŸ–‹ï¸ **Ø§Ù„Ù…Ø¤Ù„Ù Ø£Ùˆ Ø§Ù„Ø¬Ù‡Ø© Ø§Ù„Ù…Ø¹Ø¯Ù‘Ø©**
- ğŸ“˜ **Ø§Ù„Ø®Ù„Ø§ØµØ©:** (Ø³Ø·Ø±ÙŠÙ† Ù„Ø£Ù‡Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬)

ğŸ’¡ ÙÙŠ Ø­Ø§Ù„ ÙˆØ¬ÙˆØ¯ Ø­Ø³Ø§Ø¨Ø§Øª Ù…Ø§Ù„ÙŠØ© Ø£Ùˆ Ù†Ø³Ø¨:
Ø§ÙƒØªØ¨Ù‡Ø§ Ø¨Ø®Ø·ÙˆØ§Øª ÙˆØ§Ø¶Ø­Ø©:
- Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©  
- Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©  
- Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ  

ğŸ“‘ Ø¹Ù†Ø¯ Ø§ÙƒØªØ´Ø§Ù ØªØ¹Ø¯ÙŠÙ„Ø§Øª ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø£Ùˆ Ø§Ù„Ù„ÙˆØ§Ø¦Ø­:
- Ø§Ø¹Ø±Ø¶Ù‡Ø§ ÙÙŠ Ø´ÙƒÙ„ Ø¬Ø¯ÙˆÙ„ Ù…Ù†Ø³Ù‚ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
  | Ø§Ù„Ø¨Ù†Ø¯ | Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø¯ÙŠÙ… | Ø§Ù„Ù†Øµ Ø§Ù„Ø¬Ø¯ÙŠØ¯ | Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø© Ø£Ùˆ Ù†ÙˆØ¹ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ |
- Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø¯ÙŠÙ… ÙÙŠ Ø§Ù„Ù…Ù„ÙØŒ Ø§ÙƒØªÙÙ Ø¨Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø¹Ø¯Ù‘Ù„ Ù…Ø¹ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„Ù‰ Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø©.
- Ø§Ø­Ø±Øµ Ø£Ù† ØªÙƒÙˆÙ† ØµÙŠØ§ØºØ© Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù…Ù†Ø¸Ù…Ø© ÙˆÙˆØ§Ø¶Ø­Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù….

ğŸ—‚ï¸ Ù…ÙˆØ§Ù‚Ù Ø®Ø§ØµØ© ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©:
- Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù† "Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù" Ø£Ùˆ "Ù…Ø§ ÙŠØ­ØªÙˆÙŠÙ‡ Ø§Ù„Ù…Ù„Ù" Ø£Ùˆ "Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„"ØŒ
  ÙØ§ÙØªØ±Ø¶ Ø£Ù†Ù‡ ÙŠØ±ÙŠØ¯ Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚Ø¯Ù… Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø£Ùˆ Ù…Ù„Ø®ØµÙ‹Ø§ ØªÙØµÙŠÙ„ÙŠÙ‹Ø§ Ù„Ù‡.
  Ø¹Ù†Ø¯Ù‡Ø§:
  - Ù‚Ø¯Ù‘Ù… ØªÙ„Ø®ÙŠØµÙ‹Ø§ Ø´Ø§Ù…Ù„Ù‹Ø§ Ù„Ù…Ø¶Ù…ÙˆÙ† Ø§Ù„Ù†Øµ Ø¨ÙˆØ¶ÙˆØ­ØŒ Ù…Ø¹ Ø°ÙƒØ± Ù†ÙˆØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯.
  - Ù„Ø§ ØªÙ‚Ù„ "Ù„Ù… ÙŠØªÙ… Ø¥Ø±ÙØ§Ù‚ Ù…Ù„Ù"ØŒ Ø­ØªÙ‰ Ù„Ùˆ Ù„Ù… ÙŠÙØ°ÙƒØ± Ø§Ø³Ù… Ù…Ù„Ù ØµØ±Ø§Ø­Ø©.
- Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø¹Ù† "Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ù„Ù"ØŒ Ø£Ø¹Ø·Ù Ù…Ù„Ø®ØµÙ‹Ø§ Ù…Ø±ÙƒØ²Ù‹Ø§ ÙÙŠ ÙÙ‚Ø±Ø§Øª Ø£Ùˆ Ù†Ù‚Ø§Ø·.

ğŸ§  Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªÙÙƒÙŠØ±:
- Ø§ÙÙ‡Ù… Ø§Ù„ÙÙƒØ±Ø© Ø£ÙˆÙ„Ù‹Ø§ Ø«Ù… Ø­Ù„Ù‘Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ.
- Ø§Ø±Ø¨Ø· Ø¨ÙŠÙ† Ø§Ù„Ø¨Ù†ÙˆØ¯ ÙˆØ§Ù„Ù…ÙˆØ§Ø¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ù„Ø§Ù‚Ø© Ù…Ù†Ø·Ù‚ÙŠØ©.
- Ø¹Ù†Ø¯ Ø§Ù„ØºÙ…ÙˆØ¶ØŒ Ø¨ÙŠÙ‘Ù† Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© ("Ù…Ø¤ÙƒØ¯"ØŒ "Ù…Ø­ØªÙ…Ù„"ØŒ "Ø§Ø³ØªÙ†ØªØ§Ø¬").
- Ù„Ø§ ØªØ·Ù„Ø¨ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† {context} ÙØ§Ø±ØºÙ‹Ø§ ÙØ¹Ù„Ø§Ù‹.

ğŸ§© Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙØ§Ø¹Ù„:
Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù†Øµ ÙÙŠ {context}:
> "ğŸ“„ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯: ..."  
Ø«Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„.

Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ù†Øµ:
> "Ù„Ù… Ø£Ø³ØªÙ„Ù… Ù†Øµ Ø§Ù„Ù…Ù„Ù. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø£Ùˆ Ù„ØµÙ‚ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§."

Ø§Ù„Ù…Ø¹Ø·ÙŠØ§Øª: {context}
Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {question}
Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
"""



    # Ù†Ø¹Ù…Ù„ Ù‚Ø§Ù„Ø¨ (Template) Ù†Ù‚Ø¯Ø± Ù†Ù…Ø±Ø± Ù„Ù‡ Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ø³Ø¤Ø§Ù„
    prompt = PromptTemplate(template=PROMPT, input_variables=["context", "question"])



    # Ù†Ø®ØªØ§Ø± Ù…ÙˆØ¯ÙŠÙ„ Groq (ØªÙ‚Ø¯Ø± ØªØºÙŠÙ‘Ø± Ù†ÙˆØ¹Ù‡ Ø­Ø³Ø¨ Ø§Ø­ØªÙŠØ§Ø¬Ùƒ)
    model = ChatGroq(
        model="openai/gpt-oss-120b",  # Ù…ÙˆØ¯ÙŠÙ„ Ø°ÙƒÙŠ ÙˆÙ…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ©
        temperature=0.2,       # Ø±Ù‚Ù… Ù…Ù†Ø®ÙØ¶ ÙŠØ¹Ù†ÙŠ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ«Ø§Ø¨ØªØ©
        groq_api_key=os.getenv("GROQ_API_KEY")  # Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API Ù…Ù† Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©
    )

    # Ù†Ø­Ù…Ù„ Ø³Ù„Ø³Ù„Ø© Ø³Ø¤Ø§Ù„ ÙˆØ¬ÙˆØ§Ø¨ ØªØ±Ø¨Ø· Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¨Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
    chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)

    context_text = "\n".join([doc.page_content for doc in docs])
    st.write("ğŸ§¾ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„Ù€ context:", len(context_text))
    st.write("ğŸ“„ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø£ÙˆÙ„ 500 Ø­Ø±Ù:", context_text[:500])


    # Ù†Ø±Ø³Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡
    response = chain({"input_documents": docs, "question": user_question, "context": context_text}, return_only_outputs=True)

    # Ù†Ø±Ø¬Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù†Ø§ØªØ¬ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
    return response["output_text"]




def main():
  load_dotenv()
  st.set_page_config("Ø§Ù„Ø±ÙˆØ¨ÙˆØª Ø§Ù„Ø°ÙƒÙŠ", page_icon="ğŸ¤–")
  if "chat_history" not in st.session_state:
      st.session_state.chat_history = []
  st.title("ğŸ¤– Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø°ÙƒÙŠ")
  st.markdown("""
          <p style='text-align: center; color: #FFF7; font-family: Tajawal'>
            Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ ÙˆØ§Ø³Ø£Ù„ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø¹Ù†Ù‡Ø§ â€“ Ø³ÙŠÙ‚ÙˆÙ… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ Ø¥Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù.
        </p>
""", True)
  st.write(css, unsafe_allow_html=True)
  st.markdown("""<div class='overlay'></div>""", True)
  PDFS = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„ÙØ§ØªÙƒ Ù…Ù† Ù‡Ù†Ø§", type="pdf", accept_multiple_files=True)
  if PDFS:
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©... "):
      #Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ø§Ù… Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ PDF
      GET_TEXT = GET_TEXT_FROM_PDF(PDFS)

      # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¹Ù„ÙŠ Ø´ÙƒÙ„ Ù…Ù‚Ø§Ø·Ø¹
      SPLIT_TEXT_TO_CHUNK = SPLITTEXTTOCHUNK(GET_TEXT)
      for PDF in PDFS:
        filename = os.path.splitext(PDF.name)[0]
        STORE = CREATESTORE(SPLIT_TEXT_TO_CHUNK, filename)
      # Ø§Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª

    user_question = st.chat_input("Ø£Ø³Ø§Ù„ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§")
    if (user_question):

        answer = ASK_PDF_QUESTION(STORE, user_question)
        st.session_state.chat_history.append({
            "question": user_question ,
            "answer": answer
        })
        if st.session_state.chat_history:
            for chat in st.session_state.chat_history:
              # ğŸ”¹ ÙŠØ­ÙˆÙ„ Ø£ÙŠ Ù„ÙŠÙ†Ùƒ Ù†ØµÙŠ Ø¥Ù„Ù‰ Ø±Ø§Ø¨Ø· HTML Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø¶ØºØ·
              def make_links_clickable(text):
                # ÙŠØ­ÙˆÙ‘Ù„ Ø£ÙŠ Ù„ÙŠÙ†Ùƒ (Ø­ØªÙ‰ Ø§Ù„Ù„ÙŠ Ù…Ù† ØºÙŠØ± http) Ø¥Ù„Ù‰ Ø±Ø§Ø¨Ø· Ù‚Ø§Ø¨Ù„ Ù„Ù„Ø¶ØºØ·
                url_pattern = r'((?:https?://)?(?:www\.)?[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}(?:/[^\s<>"]*)?)'
                def repl(match):
                  url = match.group(0)
                  if not url.startswith("http"):
                    url = "https://" + url
                  return f'<a href="{url}" target="_blank" style="color:#4fc3f7; text-decoration:underline;">{match.group(0)}</a> ğŸ”—'
                return re.sub(url_pattern, repl, text)


              st.markdown(f"""
        <div style='background-color:rgb(255 255 255 / 4%); backdrop-filter: blur(10px); font-size:18px ;  color:#FFF; direction: rtl ; font-family:tajawal ;padding:10px; border-radius:10px; margin-top:10px;'>
            <span style="color: rgb(197 197 197); margin-bottom: 6px; display:inline-block; font-weight:bold"> ğŸ™‹â€â™‚ï¸ Ø³Ø¤Ø§Ù„Ùƒ</span><br>{chat["question"]}
                    </div>
  """, unsafe_allow_html=True)
              st.markdown(f"""
            <div style='background-color:#FFF1; font-size:18px ;color:#FFF; direction: rtl ;  font-family:tajawal ;padding:10px; border-radius:10px; margin-top:10px;'>
                        <span style='color:#009688; margin-bottom: 6px; display:inline-block; font-weight:bold'>ğŸ¤– Ø±Ø¯ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ</span><br>{make_links_clickable(chat["answer"])}
                        </div>
  """, unsafe_allow_html=True)



if __name__ == "__main__":
  main()