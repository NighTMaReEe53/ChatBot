import pydantic.v1
import streamlit as st
from langchain_groq import ChatGroq
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate
import os
import pickle
import re;
from dotenv import load_dotenv
import fitz
from HTMLTEMPLATE import css
from langchain.schema import Document
# import pytesseract
# from PIL import Image




# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"  # ุบููุฑ ุงููุณุงุฑ ุญุณุจ ููุงู ุงูุชุซุจูุช ุนูุฏู


def prepare_ocr_for_lm(text):
    """
    ุชูุธูู ุงููุต ุงููุงุชุฌ ูู OCR ูุจู ุฅุฑุณุงูู ูููููุฐุฌ
    """
    text = re.sub(r"\s{2,}", " ", text)
    text = re.sub(r"[^\u0600-\u06FF0-9A-Za-z\s.,()\-โโ/]", "", text)
    return text.strip()




def GET_TEXT_FROM_PDF(PDFS):
    """
    ๐ ุงุณุชุฎุฑุงุฌ ุงููุต ูู ูููุงุช PDF
    """
    full_text = ""

    for pdf in PDFS:
        pdf.seek(0)
        pdf_hash = hash(pdf.name)
        cache_file = f"cache_{pdf_hash}_smartocr.pkl"

        if os.path.exists(cache_file):
            with open(cache_file, "rb") as f:
                cached_text = pickle.load(f)
            st.info(f"๐ฆ ุชู ุชุญููู ุงููุต ูู ุงูุฐุงูุฑุฉ ุงููุคูุชุฉ (Smart OCR Cache): {pdf.name}")
            full_text += cached_text
            continue

        pdf_text = ""

        doc = fitz.open(stream=pdf.read(), filetype="pdf")
        for i, page in enumerate(doc, start=1):
            text = page.get_text("text")
            if len(text.strip()) > 0:
                pdf_text += text + "\n"
                continue

            st.info(f"โ ุงูุตูุญุฉ {i}: ูุง ุชุญุชูู ุนูู ูุตุ ุณูุชู ุงุณุชุฎุฏุงู Tesseract OCR...")

            # pix = page.get_pixmap(dpi=200)
            # img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

            # try:
            #     extracted = pytesseract.image_to_string(img, lang="ara+eng")
            # except Exception as e:
            #     st.error(f"โ ูุดู Tesseract OCR: {e}")
            #     extracted = ""

            # if extracted.strip():
            #     pdf_text += extracted + "\n"
            #     st.success(f"โ ุชู ุชุญููู ุงูุตูุญุฉ {i} ูุงุณุชุฎุฑุงุฌ ุงููุต ({len(extracted)} ุญุฑู).")
            # else:
            #     st.warning(f"โ ุงูุตูุญุฉ {i}: ูู ูุชููู OCR ูู ุงุณุชุฎุฑุงุฌ ุฃู ูุต.")

        pdf_text = re.sub(r"\s{2,}", " ", pdf_text).strip()

        with open(cache_file, "wb") as f:
            pickle.dump(pdf_text, f)

        full_text += pdf_text + "\n"

    st.success(f"๐ ุชู ุงุณุชุฎุฑุงุฌ ุงููุต ุจุงููุงูู ({len(full_text)} ุญุฑู).")

    cleaned_text = prepare_ocr_for_lm(full_text)
    return cleaned_text




def SPLITTEXTTOCHUNK(TEXT):
  SPLITTER = RecursiveCharacterTextSplitter(
    chunk_size=3500,
    chunk_overlap=500,
    separators=["\n", "ุงููุงุฏุฉ", ".", "ุ", " "]
  )
  CHUNK = SPLITTER.split_text(TEXT)
  return CHUNK


def CREATESTORE(TEXT, filename):
    """
    ๐ง ุฅูุดุงุก ุฃู ุชุญููู ูุงุนุฏุฉ ุจูุงูุงุช FAISS ุฎุงุตุฉ ุจูู ููู PDF.
    - ูุชู ุญูุธ ูู ููู ุฏุงุฎู ูุฌูุฏ faiss_index ุจุงุณู ุงูููู.
    """
    # ูุณุงุฑ ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจุงูููู
    os.makedirs("faiss_index", exist_ok=True)
    PATH = os.path.join("faiss_index", f"{filename}")

    # ุงุฎุชูุงุฑ ูููุฐุฌ Embedding
    EMBEDDING = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

    # ุงูุชุฃูุฏ ูู ูุฌูุฏ ููู ุงูููุฑุณ ูุจู ุงูุชุญููู
    if os.path.exists(f"{PATH}.index.faiss") and os.path.exists(f"{PATH}.index.faiss"):
        STORE = FAISS.load_local(PATH, EMBEDDING, index_name=filename ,allow_dangerous_deserialization=True)
        st.info(f"๐ฆ ุชู ุชุญููู ูุงุนุฏุฉ ุจูุงูุงุช {filename}")
    else:
        st.info(f"โ ุฌุงุฑู ุฅูุดุงุก ูุงุนุฏุฉ ุจูุงูุงุช ุฌุฏูุฏุฉ ููููู: {filename} ...")
        STORE = FAISS.from_texts(TEXT, embedding=EMBEDDING)
        STORE.save_local("faiss_index", index_name=filename)
        st.success(f"๐พ ุชู ุญูุธ ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงูุฎุงุตุฉ ุจุงูููู {filename} ุจูุฌุงุญ.")

    return STORE




def ASK_PDF_QUESTION(STORE, user_question):
    """
    ๐น ุงูุฏุงูุฉ ุฏู ุจุชุณุชูุจู ุณุคุงู ุงููุณุชุฎุฏูุ ูุชุณุชุฎุฏู ูุงุนุฏุฉ ุงูุจูุงูุงุช (FAISS)
    ุนูุดุงู ุชุฏูุฑ ุนูู ุฃูุณุจ ุฌุฒุก ูู ุงููุต ูุชุฌูุจ ุฅุฌุงุจุฉ ุฐููุฉ ูู ููุฏูู Groq.
    """

    context = st.session_state.get("context", "")

    # ูุจุญุซ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุนู ุงููุตูุต ุงูุฃูุฑุจ ููุณุคุงู
    docs = STORE.similarity_search(user_question, k=2)

    recent_context_text = ""
    if "chat_history" in st.session_state and len(st.session_state.chat_history) > 0:
        # ุฎุฐ ุขุฎุฑ 2 ูุญุงุฏุซุงุช (user+assistant)
        for chat in st.session_state.chat_history[-2:]:
            q = chat.get("question", "")
            a = chat.get("answer", "")
            recent_context_text += f"ูุญุงุฏุซุฉ ุณุงุจูุฉ โ ุณุคุงู ุงููุณุชุฎุฏู: {q}\nุฑุฏ ุงููุณุงุนุฏ: {a}\n\n"

    if recent_context_text:
        docs.append(Document(page_content=recent_context_text, metadata={"source": "recent_conversation"}))


    # ูุญุฏุฏ ุดูู ุงูุจุฑููุจุช (ุทุฑููุฉ ููู ุงูุณุคุงู)


    PROMPT = """
ุฃูุช ูุณุงุนุฏ ุฐูู ูููุญุชุฑู ูู ููู ูุชุญููู ุงููุตูุต **ุงููุงููููุฉุ ุงูุถุฑูุจูุฉุ ุงููุงููุฉุ ุงูุฅุฏุงุฑูุฉุ ุงูุฃูุงุฏูููุฉุ ูุงูุดุฎุตูุฉ**.  
ูููุชู ุงูุฃุณุงุณูุฉ: **ุชูุฏูุฑ ููุฉ ุงููุณุชุฎุฏู ุฃููุงู** โ ูู ูู ุจููููู ุจูุฏุ ุจูุณุฃู ุณุคุงู ุจุณูุทุ ููุง ูุนูุงู ุนุงูุฒ ุชุญูููุ  
ูุจูุงุกู ุนูููุง ุชุชุตุฑูู ุจุฐูุงุก ุทุจูุนู ุฒู ุงูุฅูุณุงู ุจุงูุถุจุท. ๐ค๐ก  

---

๐ **ูุฏุฎูุงุช ุงูุณูุงู ุงูุฃุณุงุณูุฉ:**

- ๐งพ **ุงููุต ุฃู ุงููุญุชูู:** {context}
- โ **ุณุคุงู ุงููุณุชุฎุฏู:** {question}

---

### ๐ฃ๏ธ ุฃูููุง โ ุงูููู ุงูุงุฌุชูุงุนู ูุงูุฑุฏูุฏ ุงูุฐููุฉ

1๏ธโฃ **ูู ุงููุณุชุฎุฏู ุจูุชููู ุจูุฏ ุฃู ูุฒุงุญ ุฃู ุชุญูุฉ**  
(ุฒู: "ุงูุณูุงู ุนูููู" โ "ุฅุฒูู" โ "ุนุงูู ุฅูู" โ "ุชูุงูุ" โ "ูุง ูุฌู" โ "ูุง ุบุงูู" โ "ุตุจุงุญ ุงูุฎูุฑ" โ "ูุณุงุก ุงูุฎูุฑ")  
โ ูุง ุชุญูู ููุง ุชุนุฑุถ ุฃู ูุนูููุงุช ูู ุงูููู.  
ุฑุฏ ููุท ุจุฃุณููุจ ุทุจูุนูุ ูุดุฌุนุ ูููุงุณุจ ููุบูุฉ ุงูููุงู:

- ูู ุฏูููุฉ โ "ูุนูููู ุงูุณูุงู ูุฑุญูุฉ ุงููู ูุจุฑูุงุชู ๐ธ ุฑุจูุง ูุณุนุฏู ููุดุฑุญ ุตุฏุฑู ุฏุงูููุง ๐ค"
- ูู ูุฏูุฉ โ "ุฃูุง ุชูุงู ูุง ุบุงูู ๐ุ ุฅูุช ุนุงูู ุฅููุ ุดููู ูู ูููุฏ ุดุบู ุงูููุงุฑุฏู ๐ชโจ"
- ูู ูุฒุงุญ โ "๐ ููู ุชูุงู ูุง ูุฌูุ ูุงุถุญ ุฅูู ุฑุงูู! ูุจุฏุฃ ููุง ูุงุฎุฏ ููุจุงูุฉ ุงููููุฉ ุงูุฃูู โุ"
- ูู ูููุง ุญุฒู ุฃู ุถูู โ "ุฎูุฑ ูุง ุตุงุญุจูุ โค๏ธ ุฃูุง ูุนุงู ุฎุทูุฉ ุจุฎุทูุฉุ ูุฅู ุดุงุก ุงููู ููู ูุชุญู ๐ค๏ธ"

๐ฏ **ูุฏูู ููุง:** ุชุจูู ุฅูู ูุงูู ูุดุงุนุฑ ุงููุณุชุฎุฏู ูุชุชุนุงูู ูุนุงู ูุตุงุญุจ ูุด ูุฑูุจูุช.

---

2๏ธโฃ **ูู ุงููุณุชุฎุฏู ุจูุณุฃู ุณุคุงู ุจุณูุท ุฌุฏูุง ุนู ููุณู ุฃู ุนู ููู ุดุฎุตู**  
(ุฒู: "ุงุณูู ุฅููุ" โ "ุนูุฏู ูุงู ุณูุฉุ" โ "ุจุดุชุบู ุฅููุ")  
โ ุงุณุชุฎุฏู ุงููุต ุงูููุฌูุฏ ูู {context} ูุงุณุชุฎุฑุงุฌ ุงููุนูููุฉ ุงููุทููุจุฉ ููุทุ ูุฑุฏ ุจุฅุฌุงุจุฉ ูุตูุฑุฉ ููุฑูุญุฉ.  

**ูุซุงู:**  
"ุนูุฏู 22 ุณูุฉ ๐ ููุณู ูู ุจุฏุงูุฉ ุทุฑููู ุงูุฌูููุ ุดุฏ ุญููู ูุง ุจุทู ๐ช"  
"ุงุณูู ููุณู ุนุงุฏู โจ ูุงุณู ุฌููู ุนูู ููุฑุฉ ๐"  

---

3๏ธโฃ **ูู ุงููุณุชุฎุฏู ุจูููู ุญุงุฌุฉ ุฒู โูุด ูุงูู ุงููุงููู ุฏูโ ุฃู โุดุฑุญ ุจุณูุท ูู ุณูุญุชโ**  
โ ุฑุฏ ุจููุทู ูุดุฑุญ ุงููุงููู ุจูุบุฉ ุณููุฉ ููุจุณุทุฉุ ูุฃูู ุจุชุดุฑุญ ูุตุงุญุจู ูุด ูุทุงูุจ ูู ูููุฉ ุญููู.  
ุงุจุฏุฃ ูุซููุง ุจุฌููุฉ ุชุดุฌูุนูุฉ:  
"ุชูุงู ูุง ุจุทูุ ุฎูููุง ูููููุง ูุงุญุฏุฉ ูุงุญุฏุฉ ๐"  
ุฃู  
"ููุง ูููู ูุง ุบุงููุ ุงููุงููู ุฏู ุจุณูุท ุฌุฏูุง ููุง ููุตููู ุฎุทูุฉ ุจุฎุทูุฉ โ๏ธ๐ฌ"

---

### โ๏ธ ุซุงูููุง โ ุงูุชุญููู ุงููุงูููู ูุงููููู ุงูุนููู

ูู ุงูุณุคุงู ูุนูุงู ุชุญูููู ุฃู ุฎุงุต ุจููู ูุงูููู / ุถุฑูุจู / ูุงูู / ุฅุฏุงุฑู / ุฃูุงุฏููู:  
ุญููู ุจุงุญุชุฑุงูุ ููู ุจุฃุณููุจ ุฅูุณุงูู ูุฑุงููุ ูุงูุชู ุฅู ุงููุชูุฌุฉ ุชููู **ุณููุฉ ุงูููู ููุฑูุญุฉ ููุนูู**.

#### ๐งฉ ุงูุชุญููู ุงููุงูููู:
- ุญุฏูุฏ ููุน ุงููุต (ูุงูููุ ูุงุฆุญุฉุ ูุฑุงุฑุ ุชุนุฏูู...).
- ุงุณุชุฎุฑุฌ ุงูููุงุฏ ูุงูุฃุฑูุงู ูุงููุฑุงุฌุน.
- ูุณูุฑ ุงูููุตูุฏ ุจูุบุฉ ุจุณูุทุฉ ููุงุถุญุฉ.
- ูุถูุญ ุงูุนูุงูุฉ ุจูู ุงููุงููู ุงูุฃุตูู ูุงูุชุนุฏููุงุช.
- ุจููู ุงูุฃุซุฑ ุงููุงูููู ุฃู ุงูุนููู ูููุต.
- ูู ููู ูุจุณ โ ูุณูุฑู ูุงูุชุฑุญ ุชูุถูุญูุง ููุทูููุง.  
๐ฌ *ุงุจุฏุฃ ุฏุงูููุง ุจุฌููุฉ ุชุดุฌูุนูุฉ:*  
"ุชุญููู ููุชุงุฒ ูููุตูู ุณูุง ุฎุทูุฉ ุจุฎุทูุฉ โ๏ธ๐ช"

#### ๐ฐ ุงูุชุญููู ุงูุถุฑูุจู:
- ูุถูุญ ุงูุดุฑุงุฆุญ ูุงููุณุจ ุจุงูุฃุฑูุงู.  
- ูุณูุฑ ุทุฑููุฉ ุงูุชุทุจูู ุงููุงูุนูุฉ ุจูุซุงู ุฑููู ูุจุณุท.  
๐ *ุงุจุฏุฃ ุจุฌููุฉ ูุญูุฒุฉ:*  
"ููุง ูุญุณุจูุง ุณูุง ุจุงูุฃุฑูุงู ๐ ุนูุดุงู ุงูุตูุฑุฉ ุชุจูู ุฃูุถุญ ๐ก"

#### ๐ข ุงูุฅุฏุงุฑู:
- ูุณูุฑ ุงุฎุชุตุงุต ุงูุฌูุฉ ูุชุฃุซูุฑ ุงููุฑุงุฑ.  
๐งฉ "ุฎูููุง ููููุง ุจูุฏูุก ูุฏู ููุดูู ุงูุฃุซุฑ ุงูุฅุฏุงุฑู ุฎุทูุฉ ุจุฎุทูุฉ ๐ข๐"

#### ๐ ุงูุฃูุงุฏููู:
- ูุฎูุต ุงูููุฑุฉ ุฃู ุงููููุฌ ุฃู ุงููุชุงุฆุฌ.  
๐ "ุชุญููู ุฃูุงุฏููู ููุธู ุฌุงููู ุญุงููุงุ ููููุถูุญ ุฃูู ุงูููุงุท ุงูุนูููุฉ ๐ฌ๐"

#### ๐ค ุงูุดุฎุตู:
- ุญููู ููุท ุนูุฏ ุงูุทูุจุ ูุงุญุชุฑู ุงูุฎุตูุตูุฉ.  
๐ค "ุงูููู ุฏู ุดุฎุตูุ ูุฎูููุง ูุงุฎุฏู ุจูุฏูุก ูุจุฃุณููุจ ุขูู ุชูุงููุง ๐"

---

### ๐ค ุดูู ุงูุฅุฎุฑุงุฌ (ูู ุชุญููู ูุนูู ููุท)

1๏ธโฃ ๐ **ููุน ุงูููู**
2๏ธโฃ ๐ง **ุงูููู ุงูุนุงู ูููุต**
3๏ธโฃ ๐ **ุงูููุงุท ุงูุชุญููููุฉ (ุฎุทูุงุช ุฃู ููุงุฏ)**
4๏ธโฃ ๐ฌ **ุงูุชูุณูุฑ ุฃู ุงูุญุณุงุจุงุช (ูู ุถุฑูุจูุฉ)**
5๏ธโฃ ๐ก **ุงูุชุฑุงุญุงุช ุฐููุฉ** (ุนูููุฉ ููุจุงุดุฑุฉ)
6๏ธโฃ ๐งพ **ููุฎุต ุฐูู ููุฌุฒ**

๐ช *ุฎุชู ุงูุฑุฏ ุจุฌููุฉ ุฅูุฌุงุจูุฉ ูุตูุฑุฉ ุญุณุจ ุงูุญุงูุฉ:*  
- "ุชุญููู ููุชุงุฒ ูุง ุจุทู ๐ุ ูุฏู ุงูุตูุฑุฉ ุจูุช ูุงุถุญุฉ ุฌุฏูุง! ๐ก"  
- "ุฎุฏ ุฑุงุญุชู ูู ูุญุชุงุฌ ุฃูุถุญ ุฃูุชุฑุ ุฃูุง ููุง ุฏุงูููุง ๐"  
- "ูููู ุฌููู ุฌุฏูุงุ ูููู ุนูู ููุณ ุงููุณู ๐ฅ"  

---


# โก **ุงูุฎูุงุตุฉ:**
# ูู ูู ุฑุฏูุฏู ูุฒูุฌูุง ุจูู:
# - ๐น ูุณุชุดุงุฑ ูุงูููู ุถุฑูุจู ูุชูุฑุณ (ูู ุงููููุงุช ุงููุงููููุฉ ูุงููุงููุฉ)
# - ๐น ูุญูู ุฅุฏุงุฑู ุฃู ุฃูุงุฏููู ุฏููู (ูู ุงููุซุงุฆู ุงูุชูุธูููุฉ ุฃู ุงูุจุญุซูุฉ)
# - ๐น ูุณุงุนุฏ ูุฏูุฏ ุฐูู (ูู ุงููููุงุช ุงูุดุฎุตูุฉ)


### โ๏ธ ุงูููุงุนุฏ ุงูุฐููุฉ:

- ูู ุงูุณุคุงู ุจุณูุท ุฃู ูุฏู โ **ุฑุฏ ุทุจูุนู ุจูุง ุชุญููู.**
- ูู ููู ุทูุจ ููููู ุฃู ุงูุดุฑุญ โ **ุงุดุฑุญ ุจูุบุฉ ุณููุฉ ููุงุถุญุฉ ููุดุฌุนุฉ.**
- ูู ุงูููู ูุงูููู ุฃู ุถุฑูุจู โ **ุญููู ุจุงุญุชุฑุงู ูุงูููู ุฏููู.**
- ูู ุงููุณุชุฎุฏู ูุชูุชุฑ โ **ุงุณุชุฎุฏู ูุจุฑุฉ ูุงุฏูุฉ ููุทูุฆูุฉ.**
- ูู ุงูููู ุดุฎุตู ุฌุฏูุง โ **ุฐููุฑู ุจุงูุฎุตูุตูุฉ ุจููุทู.**

---

๐ฏ ุงููุฏู:
ุชููู ูุณุงุนุฏ ุทุจูุนู ูุฐูู ูู ูู ุงูุญุงูุงุช:
- ๐ฌ ุชููู ุงูุฅูุณุงู ูุจู ุงููุต.
- โ๏ธ ุชููู ุงููุงููู ุจุนูู.
- ๐ค ุชุชุนุงูู ุจูุฏ ูุชุดุฌูุน.
- ๐ ูุชุฑุฏ ูุฎุจูุฑ ูุงููู ูุด ูุฌุฑุฏ ุจูุช.
"""



    # ูุนูู ูุงูุจ (Template) ููุฏุฑ ููุฑุฑ ูู ุงููุต ูุงูุณุคุงู
    prompt = PromptTemplate(template=PROMPT, input_variables=["context", "question"])



    # ูุฎุชุงุฑ ููุฏูู Groq (ุชูุฏุฑ ุชุบููุฑ ููุนู ุญุณุจ ุงุญุชูุงุฌู)
    model = ChatGroq(
        # model="openai/gpt-oss-120b",  # ููุฏูู ุฐูู ูููุงุณุจ ููุฃุณุฆูุฉ ุงูุชุญููููุฉ
        model="openai/gpt-oss-20b",  # ููุฏูู ุฐูู ูููุงุณุจ ููุฃุณุฆูุฉ ุงูุชุญููููุฉ
        temperature=0.2,       # ุฑูู ููุฎูุถ ูุนูู ุฅุฌุงุจุงุช ุฏูููุฉ ูุซุงุจุชุฉ
        groq_api_key=os.getenv("GROQ_API_KEY")  # ููุชุงุญ ุงูู API ูู ูุชุบูุฑ ุงูุจูุฆุฉ
    )

    # ูุญูู ุณูุณูุฉ ุณุคุงู ูุฌูุงุจ ุชุฑุจุท ุงูููุฏูู ุจุงูุจุฑููุจุช
    chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)

    context_text = "\n".join([doc.page_content for doc in docs])


    # ูุฑุณู ุงูุณุคุงู ููููุฏูู ูุน ุงููุตูุต ุงููุฑุชุจุทุฉ ุจู
    response = chain({"input_documents": docs, "question": user_question, "context": context_text if context_text.strip() else context}, return_only_outputs=True)

    # ูุฑุฌุน ุงููุต ุงูููุงุฆู ุงููุงุชุฌ ูู ุงูููุฏูู
    return response["output_text"]




def main():
  load_dotenv()
  st.set_page_config("ุงูุฑูุจูุช ุงูุฐูู", page_icon="๐ค")
  if "chat_history" not in st.session_state:
      st.session_state.chat_history = []
  st.title("๐ค ุงููุณุชุดุงุฑ ุงููุงูููู ุงูุฐูู")
  st.markdown("""
          <p style='text-align: center; color: #FFF7; font-family: Tajawal'>
            ุงุฑูุน ูููุงุชู ูุงุณุฃู ุฃู ุณุคุงู ุนููุง โ ุณูููู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุจุงูุฅุฌุงุจุฉ ุงุณุชูุงุฏูุง ุฅูู ูุญุชูู ุงูููู.
        </p>
""", True)
  st.write(css, unsafe_allow_html=True)
  st.markdown("""<div class='overlay'></div>""", True)
  PDFS = st.file_uploader("ุงุฑูุน ูููุงุชู ูู ููุง", type="pdf", accept_multiple_files=True)
  if PDFS:
    with st.spinner("โณ ุฌุงุฑู ุงููุนุงูุฌุฉ... "):
      #ุงุณุชุฎุฑุงุฌ ุงูููุงู ูู ุงููููุงุช ุงู PDF
      GET_TEXT = GET_TEXT_FROM_PDF(PDFS)

      st.session_state.context = GET_TEXT

      # ุชูุณูู ุงููููุงุช ุนูู ุดูู ููุงุทุน
      SPLIT_TEXT_TO_CHUNK = SPLITTEXTTOCHUNK(GET_TEXT)
      for PDF in PDFS:
        filename = os.path.splitext(PDF.name)[0]
        STORE = CREATESTORE(SPLIT_TEXT_TO_CHUNK, filename)
      # ุงูุดุงุก ูุงุนุฏุฉ ุจูุงูุงุช

    user_question = st.chat_input("ุฃุณุงู ุณุคุงูู ููุง")
    if (user_question):

        answer = ASK_PDF_QUESTION(STORE, user_question)
        st.session_state.chat_history.append({
            "question": user_question ,
            "answer": answer
        })
        if st.session_state.chat_history:
            for chat in st.session_state.chat_history:
              # ๐น ูุญูู ุฃู ูููู ูุตู ุฅูู ุฑุงุจุท HTML ูุงุจู ููุถุบุท
              def make_links_clickable(text):
                # ูุญููู ุฃู ูููู (ุญุชู ุงููู ูู ุบูุฑ http) ุฅูู ุฑุงุจุท ูุงุจู ููุถุบุท
                url_pattern = r'((?:https?://)?(?:www\.)?[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}(?:/[^\s<>"]*)?)'
                def repl(match):
                  url = match.group(0)
                  if not url.startswith("http"):
                    url = "https://" + url
                  return f'<a href="{url}" target="_blank" style="color:#4fc3f7; text-decoration:underline;">{match.group(0)}</a> ๐'
                return re.sub(url_pattern, repl, text)


              st.markdown(f"""
        <div style='background-color:rgb(255 255 255 / 4%); backdrop-filter: blur(10px); font-size:18px ;  color:#FFF; direction: rtl ; font-family:tajawal ;padding:10px; border-radius:10px; margin-top:10px;'>
            <span style="color: #F05; margin-bottom: 6px; display:inline-block; font-weight:bold"> ๐โโ๏ธ ุณุคุงูู</span><br>{chat["question"]}
                    </div>
  """, unsafe_allow_html=True)
              st.markdown(f"""
            <div style='background-color:#FFF1; font-size:18px ;color:#FFF; direction: rtl ;  font-family:tajawal ;padding:10px; border-radius:10px; margin-top:10px;'>
                        <span style='color:#4CAF50; margin-bottom: 6px; display:inline-block; font-weight:bold'>๐ค ุงููุณุชุดุงุฑ ุงููุงูููู</span><br>{make_links_clickable(chat["answer"])}
                        </div>
  """, unsafe_allow_html=True)



if __name__ == "__main__":
  main()